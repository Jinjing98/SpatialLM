{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SpatialLM Inference Notebook\n",
        "This notebook breaks down the inference.py workflow into interactive cells."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/mnt/cluster/environments/jinjingxu/pkg/envs/spatiallm/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
            "[Open3D INFO] WebRTC GUI backend enabled.\n",
            "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
            "✓ Imports loaded\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: Imports and Constants\n",
        "import os\n",
        "import sys\n",
        "import glob\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from threading import Thread\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from transformers import TextIteratorStreamer, set_seed\n",
        "\n",
        "# Add project root to path\n",
        "PROJ_PATH = \"/mnt/cluster/workspaces/jinjingxu/proj/vlm/SpatialLM\"\n",
        "DATA_ROOT = '/data/horse/ws/jixu233b-metadata_ws/datasets/arkitscenes-spatiallm/'\n",
        "DATA_ROOT = '/mnt/nct-zfs/TCO-All/SharedDatasets/arkitscenes-spatiallm/'\n",
        "\n",
        "PROJECT_ROOT = Path(PROJ_PATH)\n",
        "sys.path.insert(0, str(PROJECT_ROOT))\n",
        "\n",
        "from spatiallm import Layout\n",
        "from spatiallm.pcd import load_o3d_pcd, get_points_and_colors, cleanup_pcd, Compose\n",
        "\n",
        "DETECT_TYPE_PROMPT = {\n",
        "    \"all\": \"Detect walls, doors, windows, boxes.\",\n",
        "    \"arch\": \"Detect walls, doors, windows.\",\n",
        "    \"object\": \"Detect boxes.\",\n",
        "}\n",
        "\n",
        "print(\"✓ Imports loaded\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Helper functions defined\n"
          ]
        }
      ],
      "source": [
        "# Cell 2: Define Helper Functions\n",
        "\n",
        "def preprocess_point_cloud(points, colors, grid_size, num_bins):\n",
        "    \"\"\"Preprocess point cloud into tensor features.\"\"\"\n",
        "    transform = Compose([\n",
        "        dict(type=\"PositiveShift\"),\n",
        "        dict(type=\"NormalizeColor\"),\n",
        "        dict(\n",
        "            type=\"GridSample\",\n",
        "            grid_size=grid_size,\n",
        "            hash_type=\"fnv\",\n",
        "            mode=\"test\",\n",
        "            keys=(\"coord\", \"color\"),\n",
        "            return_grid_coord=True,\n",
        "            max_grid_coord=num_bins,\n",
        "        ),\n",
        "    ])\n",
        "    point_cloud = transform({\n",
        "        \"name\": \"pcd\",\n",
        "        \"coord\": points.copy(),\n",
        "        \"color\": colors.copy(),\n",
        "    })\n",
        "    coord = point_cloud[\"grid_coord\"]\n",
        "    xyz = point_cloud[\"coord\"]\n",
        "    rgb = point_cloud[\"color\"]\n",
        "    point_cloud = np.concatenate([coord, xyz, rgb], axis=1)\n",
        "    return torch.as_tensor(np.stack([point_cloud], axis=0))\n",
        "\n",
        "\n",
        "def generate_layout(model, point_cloud, tokenizer, code_template_file, \n",
        "                    top_k=10, top_p=0.95, temperature=0.6, num_beams=1,\n",
        "                    seed=-1, max_new_tokens=4096, detect_type=\"all\", categories=[]):\n",
        "    \"\"\"Generate layout from point cloud using the model.\"\"\"\n",
        "    if seed >= 0:\n",
        "        set_seed(seed)\n",
        "    \n",
        "    with open(code_template_file, \"r\") as f:\n",
        "        code_template = f.read()\n",
        "    \n",
        "    task_prompt = DETECT_TYPE_PROMPT[detect_type]\n",
        "    if detect_type != \"arch\" and categories:\n",
        "        task_prompt = task_prompt.replace(\"boxes\", \", \".join(categories))\n",
        "    print(\"Task prompt:\", task_prompt)\n",
        "    \n",
        "    prompt = f\"<|point_start|><|point_pad|><|point_end|>{task_prompt} The reference code is as followed: {code_template}\"\n",
        "    \n",
        "    if model.config.model_type == \"spatiallm_qwen\":\n",
        "        conversation = [\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt},\n",
        "        ]\n",
        "    else:\n",
        "        conversation = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    \n",
        "    input_ids = tokenizer.apply_chat_template(conversation, add_generation_prompt=True, return_tensors=\"pt\")\n",
        "    input_ids = input_ids.to(model.device)\n",
        "    \n",
        "    streamer = TextIteratorStreamer(tokenizer, timeout=20.0, skip_prompt=True, skip_special_tokens=True)\n",
        "    \n",
        "    generate_kwargs = dict(\n",
        "        {\"input_ids\": input_ids, \"point_clouds\": point_cloud},\n",
        "        streamer=streamer,\n",
        "        max_new_tokens=max_new_tokens,\n",
        "        do_sample=True,\n",
        "        use_cache=True,\n",
        "        temperature=temperature,\n",
        "        top_p=top_p,\n",
        "        top_k=top_k,\n",
        "        num_beams=num_beams,\n",
        "    )\n",
        "    t = Thread(target=model.generate, kwargs=generate_kwargs)\n",
        "    t.start()\n",
        "    \n",
        "    print(\"Generating layout...\\\\n\")\n",
        "    generate_texts = []\n",
        "    for text in streamer:\n",
        "        generate_texts.append(text)\n",
        "        print(text, end=\"\", flush=True)\n",
        "    print(\"\\\\nDone!\")\n",
        "    \n",
        "    layout_str = \"\".join(generate_texts)\n",
        "    layout = Layout(layout_str)\n",
        "    layout.undiscretize_and_unnormalize(num_bins=model.config.point_config[\"num_bins\"])\n",
        "    return layout\n",
        "\n",
        "print(\"✓ Helper functions defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Parameters configured\n"
          ]
        }
      ],
      "source": [
        "# Cell 3: Set Parameters\n",
        "DATA_ROOT = Path(DATA_ROOT)\n",
        "\n",
        "# Input/Output paths\n",
        "point_cloud_path = DATA_ROOT / \"pcd/40753679.ply\"\n",
        "output_path = PROJECT_ROOT / \"outputs/scene40753679.txt\"\n",
        "\n",
        "# Model configuration\n",
        "model_path = \"manycore-research/SpatialLM1.1-Qwen-0.5B\"\n",
        "disable_flash_attn = True  # Set to True for V100/older GPUs, False for A100+\n",
        "VLM_PE = None  # None: standard 1D RoPE (default), \"CCA_2DProj\": Concentric Causal Attention with 2D projection\n",
        "\n",
        "# Inference parameters\n",
        "detect_type = \"all\"\n",
        "categories = []\n",
        "code_template_file = str(PROJECT_ROOT / \"code_template.txt\")\n",
        "\n",
        "# Generation parameters\n",
        "top_k = 10\n",
        "top_p = 0.95\n",
        "temperature = 0.6\n",
        "num_beams = 1\n",
        "seed = -1\n",
        "max_new_tokens = 4096\n",
        "inference_dtype = \"bfloat16\"\n",
        "no_cleanup = False\n",
        "\n",
        "# Optional: JSON file to filter specific samples\n",
        "json_file = None\n",
        "\n",
        "print(\"✓ Parameters configured\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== CUDA Diagnostic ===\n",
            "PyTorch version: 2.4.1+cu124\n",
            "CUDA available: True\n",
            "CUDA version: 12.4\n",
            "CUDA device count: 1\n",
            "Current CUDA device: 0\n",
            "Device name: NVIDIA GeForce RTX 2080 Ti\n",
            "Device capability: (7, 5)\n",
            "\n",
            "Python executable: /mnt/cluster/environments/jinjingxu/pkg/envs/spatiallm/bin/python\n",
            "Python version: 3.11.14\n",
            "\n",
            "✓ CUDA initialization successful\n",
            "✓ Test tensor created on CUDA: cuda:0\n"
          ]
        }
      ],
      "source": [
        "# Cell 4: Diagnostic - Check CUDA Status\n",
        "import torch\n",
        "import sys\n",
        "\n",
        "print(\"=== CUDA Diagnostic ===\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "print(f\"CUDA version: {torch.version.cuda}\")\n",
        "print(f\"CUDA device count: {torch.cuda.device_count()}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"Current CUDA device: {torch.cuda.current_device()}\")\n",
        "    print(f\"Device name: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"Device capability: {torch.cuda.get_device_capability(0)}\")\n",
        "\n",
        "print(f\"\\nPython executable: {sys.executable}\")\n",
        "print(f\"Python version: {sys.version.split()[0]}\")\n",
        "\n",
        "# Try to initialize CUDA explicitly\n",
        "try:\n",
        "    torch.cuda.init()\n",
        "    print(\"\\n✓ CUDA initialization successful\")\n",
        "except Exception as e:\n",
        "    print(f\"\\n✗ CUDA initialization failed: {e}\")\n",
        "\n",
        "# Try to create a small tensor on CUDA\n",
        "try:\n",
        "    test_tensor = torch.zeros(1).cuda()\n",
        "    print(f\"✓ Test tensor created on CUDA: {test_tensor.device}\")\n",
        "    del test_tensor\n",
        "except Exception as e:\n",
        "    print(f\"✗ Failed to create tensor on CUDA: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading model from manycore-research/SpatialLM1.1-Qwen-0.5B...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/mnt/cluster/environments/jinjingxu/pkg/envs/spatiallm/lib/python3.11/site-packages/spconv/pytorch/functional.py:51: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  _TORCH_CUSTOM_FWD = amp.custom_fwd(cast_inputs=torch.float16)\n",
            "/mnt/cluster/environments/jinjingxu/pkg/envs/spatiallm/lib/python3.11/site-packages/spconv/pytorch/functional.py:100: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  @_TORCH_CUSTOM_BWD\n",
            "/mnt/cluster/environments/jinjingxu/pkg/envs/spatiallm/lib/python3.11/site-packages/spconv/pytorch/functional.py:166: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  @_TORCH_CUSTOM_BWD\n",
            "/mnt/cluster/environments/jinjingxu/pkg/envs/spatiallm/lib/python3.11/site-packages/spconv/pytorch/functional.py:246: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  @_TORCH_CUSTOM_BWD\n",
            "/mnt/cluster/environments/jinjingxu/pkg/envs/spatiallm/lib/python3.11/site-packages/spconv/pytorch/functional.py:335: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  @_TORCH_CUSTOM_BWD\n",
            "/mnt/cluster/environments/jinjingxu/pkg/envs/spatiallm/lib/python3.11/site-packages/spconv/pytorch/functional.py:372: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  @_TORCH_CUSTOM_BWD\n",
            "/mnt/cluster/environments/jinjingxu/pkg/envs/spatiallm/lib/python3.11/site-packages/spconv/pytorch/functional.py:392: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  @_TORCH_CUSTOM_BWD\n",
            "/mnt/cluster/environments/jinjingxu/pkg/envs/spatiallm/lib/python3.11/site-packages/spconv/pytorch/functional.py:415: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  @_TORCH_CUSTOM_BWD\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 2 PE in Sonata Model:\n",
            "Enc stage:\n",
            "Enable flash attention: False. Enable RPE: False.\n",
            "Apply APE in SerializedAttention\n",
            "Input_proj stage:\n",
            "Enable Fourier Encode: True.\n",
            "✓ Model loaded\n",
            "  - Type: spatiallm_qwen\n",
            "  - Bins: 1280\n",
            "  - Device: cuda:0\n",
            "  - FlashAttention: False\n",
            "  - VLM_PE: None (standard RoPE)\n"
          ]
        }
      ],
      "source": [
        "# Cell 4: Load Model and Tokenizer\n",
        "print(f\"Loading model from {model_path}...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "\n",
        "# Check if we need to modify config\n",
        "if disable_flash_attn or VLM_PE is not None:\n",
        "    from transformers import AutoConfig\n",
        "    config = AutoConfig.from_pretrained(model_path, trust_remote_code=True)\n",
        "    # Disable flash attention if requested\n",
        "    if disable_flash_attn:\n",
        "        if hasattr(config, 'point_config'):\n",
        "            config.point_config['enable_flash'] = False\n",
        "    # Set VLM_PE if specified\n",
        "    if VLM_PE is not None:\n",
        "        config.VLM_PE = VLM_PE\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_path, \n",
        "        config=config,\n",
        "        torch_dtype=getattr(torch, inference_dtype)\n",
        "    )\n",
        "else:\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_path,\n",
        "        torch_dtype=getattr(torch, inference_dtype)\n",
        "    )\n",
        "\n",
        "model.to(\"cuda\")\n",
        "model.set_point_backbone_dtype(torch.float32)\n",
        "model.eval()\n",
        "\n",
        "num_bins = model.config.point_config[\"num_bins\"]\n",
        "\n",
        "print(f\"✓ Model loaded\")\n",
        "print(f\"  - Type: {model.config.model_type}\")\n",
        "print(f\"  - Bins: {num_bins}\")\n",
        "print(f\"  - Device: {model.device}\")\n",
        "print(f\"  - FlashAttention: {not disable_flash_attn}\")\n",
        "print(f\"  - VLM_PE: {VLM_PE if VLM_PE is not None else 'None (standard RoPE)'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pointcloud path:  /mnt/nct-zfs/TCO-All/SharedDatasets/arkitscenes-spatiallm/pcd/40753679.ply\n",
            "✓ Found 1 file(s)\n",
            "  [1] 40753679.ply\n"
          ]
        }
      ],
      "source": [
        "print('Pointcloud path: ', point_cloud_path)\n",
        "# Cell 5: Discover Point Cloud Files\n",
        "if os.path.isfile(point_cloud_path):\n",
        "    point_cloud_files = [point_cloud_path]\n",
        "else:\n",
        "    if json_file is not None:\n",
        "        print(f\"Loading samples from JSON: {json_file}\")\n",
        "        with open(json_file, \"r\") as f:\n",
        "            json_data = json.load(f)\n",
        "        \n",
        "        point_cloud_files = []\n",
        "        for item in json_data:\n",
        "            pcd_files = []\n",
        "            if isinstance(item, str):\n",
        "                pcd_files = [item]\n",
        "            elif isinstance(item, dict):\n",
        "                value = (item.get(\"point_clouds\") or item.get(\"point_cloud\") or \n",
        "                        item.get(\"file_name\") or item.get(\"pcd_file\") or \n",
        "                        item.get(\"scene_id\") or item.get(\"id\"))\n",
        "                pcd_files = value if isinstance(value, list) else [value] if value else []\n",
        "            \n",
        "            for pcd_file in pcd_files:\n",
        "                pcd_file = pcd_file.replace(\"pcd/\", \"\")\n",
        "                if not pcd_file.endswith(\".ply\"):\n",
        "                    pcd_file = f\"{pcd_file}.ply\"\n",
        "                \n",
        "                full_path = os.path.join(point_cloud_path, pcd_file)\n",
        "                if os.path.exists(full_path):\n",
        "                    point_cloud_files.append(full_path)\n",
        "                else:\n",
        "                    print(f\"Warning: Not found: {full_path}\")\n",
        "        print(f\"Found {len(point_cloud_files)} samples from JSON\")\n",
        "    else:\n",
        "        point_cloud_files = glob.glob(os.path.join(point_cloud_path, \"*.ply\"))\n",
        "\n",
        "print(f\"✓ Found {len(point_cloud_files)} file(s)\")\n",
        "for i, f in enumerate(point_cloud_files[:5]):\n",
        "    print(f\"  [{i+1}] {os.path.basename(f)}\")\n",
        "if len(point_cloud_files) > 5:\n",
        "    print(f\"  ... +{len(point_cloud_files)-5} more\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing: 40753679.ply\n",
            "✓ Point cloud loaded\n",
            "  - Points: 148586\n",
            "  - Range: [-0.80251148 -3.29999995 -1.80055124] to [5.89757013 2.07263744 1.30499995]\n",
            "  - Grid: 0.025\n",
            "✓ Preprocessed: torch.Size([1, 106328, 9])\n"
          ]
        }
      ],
      "source": [
        "# Cell 6: Load and Preprocess Point Cloud\n",
        "current_file_idx = 0\n",
        "point_cloud_file = point_cloud_files[current_file_idx]\n",
        "print(f\"Processing: {os.path.basename(point_cloud_file)}\")\n",
        "\n",
        "point_cloud = load_o3d_pcd(str(point_cloud_file))\n",
        "grid_size = Layout.get_grid_size(num_bins)\n",
        "\n",
        "if not no_cleanup:\n",
        "    point_cloud = cleanup_pcd(point_cloud, voxel_size=grid_size)\n",
        "\n",
        "points, colors = get_points_and_colors(point_cloud)\n",
        "min_extent = np.min(points, axis=0)\n",
        "\n",
        "print(f\"✓ Point cloud loaded\")\n",
        "print(f\"  - Points: {len(points)}\")\n",
        "print(f\"  - Range: {np.min(points, axis=0)} to {np.max(points, axis=0)}\")\n",
        "print(f\"  - Grid: {grid_size}\")\n",
        "\n",
        "input_pcd = preprocess_point_cloud(points, colors, grid_size, num_bins)\n",
        "print(f\"✓ Preprocessed: {input_pcd.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Task prompt: Detect walls, doors, windows, boxes.\n",
            "Generating layout...\\n\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "wall_0=Wall(203,0,10,228,0,10,140,0)\n",
            "wall_1=Wall(203,0,10,185,6,10,140,0)\n",
            "wall_2=Wall(228,0,10,228,75,10,140,0)\n",
            "wall_3=Wall(185,6,10,178,10,10,140,0)\n",
            "wall_4=Wall(178,10,10,169,15,10,140,0)\n",
            "wall_5=Wall(169,15,10,160,21,10,140,0)\n",
            "wall_6=Wall(160,21,10,153,28,10,140,0)\n",
            "wall_7=Wall(153,28,10,144,34,10,140,0)\n",
            "wall_8=Wall(144,34,10,135,40,10,140,0)\n",
            "wall_9=Wall(135,40,10,124,45,10,140,0)\n",
            "wall_10=Wall(124,45,10,116,49,10,140,0)\n",
            "wall_11=Wall(116,49,10,102,56,10,140,0)\n",
            "wall_12=Wall(102,56,10,93,60,10,140,0)\n",
            "wall_13=Wall(93,60,10,87,65,10,140,0)\n",
            "wall_14=Wall(87,65,10,77,73,10,140,0)\n",
            "wall_15=Wall(77,73,10,66,83,10,140,0)\n",
            "wall_16=Wall(180,75,10,228,75,10,140,0)\n",
            "wall_17=Wall(180,75,10,180,87,10,140,0)\n",
            "wall_18=Wall(66,83,10,58,91,10,140,0)\n",
            "wall_19=Wall(180,87,10,174,96,10,140,0)\n",
            "wall_20=Wall(58,91,10,51,99,10,140,0)\n",
            "wall_21=Wall(174,96,10,167,104,10,140,0)\n",
            "wall_22=Wall(51,99,10,45,105,10,140,0)\n",
            "wall_23=Wall(167,104,10,160,111,10,140,0)\n",
            "wall_24=Wall(45,105,10,37,111,10,140,0)\n",
            "wall_25=Wall(37,111,10,28,122,10,140,0)\n",
            "wall_26=Wall(160,111,10,153,119,10,140,0)\n",
            "wall_27=Wall(153,119,10,146,128,10,140,0)\n",
            "wall_28=Wall(28,122,10,23,130,10,140,0)\n",
            "wall_29=Wall(146,128,10,136,136,10,140,0)\n",
            "wall_30=Wall(23,130,10,21,135,10,140,0)\n",
            "wall_31=Wall(21,135,10,19,139,10,140,0)\n",
            "wall_32=Wall(19,139,10,20,144,10,140,0)\n",
            "wall_33=Wall(20,144,10,23,151,10,140,0)\n",
            "wall_34=Wall(23,151,10,28,158,10,140,0)\n",
            "wall_35=Wall(28,158,10,35,164,10,140,0)\n",
            "wall_36=Wall(35,164,10,41,172,10,140,0)\n",
            "wall_37=Wall(41,172,10,49,181,10,140,0)\n",
            "wall_38=Wall(49,181,10,59,190,10,140,0)\n",
            "wall_39=Wall(59,190,10,70,200,10,140,0)\n",
            "wall_40=Wall(70,200,10,80,205,10,140,0)\n",
            "wall_41=Wall(80,205,10,90,211,10,140,0)\n",
            "wall_42=Wall(90,211,10,100,212,10,140,0)\n",
            "wall_43=Wall(100,212,10,115,212,10,140,0)\n",
            "wall_44=Wall(115,212,10,127,213,10,140,0)\n",
            "wall_45=Wall(127,213,10,140,214,10,140,0)\n",
            "wall_46=Wall(140,214,10,155,217,10,140,0)\n",
            "wall_47=Wall(155,217,10,165,220,10,140,0)\n",
            "wall_48=Wall(165,220,10,178,223,10,140,0)\n",
            "wall_49=Wall(178,223,10,188,225,10,140,0)\n",
            "wall_50=Wall(188,225,10,198,226,10,140,0)\n",
            "wall_51=Wall(198,226,10,210,226,10,140,0)\n",
            "wall_52=Wall(210,226,10,210,243,10,140,0)\n",
            "wall_53=Wall(178,228,10,188,228,10,140,0)\n",
            "wall_54=Wall(178,228,10,165,229,10,140,0)\n",
            "wall_55=Wall(188,228,10,198,228,10,140,0)\n",
            "wall_56=Wall(198,228,10,198,243,10,140,0)\n",
            "wall_57=Wall(165,229,10,155,230,10,140,0)\n",
            "wall_58=Wall(155,230,10,145,231,10,140,0)\n",
            "wall_59=Wall(145,231,10,136,232,10,140,0)\n",
            "wall_60=Wall(136,232,10,128,233,10,140,0)\n",
            "wall_61=Wall(128,233,10,120,235,10,140,0)\n",
            "wall_62=Wall(120,235,10,110,236,10,140,0)\n",
            "wall_63=Wall(110,236,10,100,238,10,140,0)\n",
            "wall_64=Wall(100,238,10,88,243,10,140,0)\n",
            "wall_65=Wall(88,243,10,77,249,10,140,0)\n",
            "wall_66=Wall(198,243,10,210,243,10,140,0)\n",
            "wall_67=Wall(77,249,10,65,254,10,140,0)\n",
            "wall_68=Wall(65,254,10,52,257,10,140,0)\n",
            "wall_69=Wall(52,257,10,40,260,10,140,0)\n",
            "wall_70=Wall(40,260,10,34,262,10,140,0)\n",
            "wall_71=Wall(34,262,10,30,263,10,140,0)\n",
            "wall_72=Wall(30,263,10,27,265,10,140,0)\n",
            "wall_73=Wall(27,265,10,25,268,10,140,0)\n",
            "wall_74=Wall(25,268,10,24,271,10,140,0)\n",
            "wall_75=Wall(24,271,10,23,274,10,140,0)\n",
            "wall_76=Wall(23,274,10,24,278,10,140,0)\n",
            "wall_77=Wall(24,278,10,26,280,10,140,0)\n",
            "wall_78=Wall(26,280,10,28,282,10,140,0)\n",
            "wall_79=Wall(28,282,10,30,283,10,140,0)\n",
            "wall_80=Wall(30,283,10,35,286,10,140,0)\n",
            "wall_81=Wall(35,286,10,40,288,10,140,0)\n",
            "wall_82=Wall(40,288,10,48,291,10,140,0)\n",
            "wall_83=Wall(48,291,10,57,292,10,140,0)\n",
            "wall_84=Wall(57,292,10,65,294,10,140,0)\n",
            "wall_85=Wall(65,294,10,76,295,10,140,0)\n",
            "wall_86=Wall(76,295,10,83,296,10,140,0)\n",
            "wall_87=Wall(83,296,10,92,297,10,140,0)\n",
            "wall_88=Wall(92,297,10,100,302,10,140,0)\n",
            "wall_89=Wall(100,302,10,115,303,10,140,0)\n",
            "wall_90=Wall(115,303,10,125,305,10,140,0)\n",
            "wall_91=Wall(125,305,10,136,307,10,140,0)\n",
            "wall_92=Wall(136,307,10,145,308,10,140,0)\n",
            "wall_93=Wall(145,308,10,155,308,10,140,0)\n",
            "wall_94=Wall(155,308,10,165,308,10,140,0)\n",
            "wall_95=Wall(165,308,10,178,308,10,140,0)\n",
            "wall_96=Wall(178,308,10,178,326,10,140,0)\n",
            "wall_97=Wall(198,326,10,178,326,10,140,0)\n",
            "wall_98=Wall(198,326,10,198,328,10,140,0)\n",
            "wall_99=Wall(198,328,10,178,328,10,140,0)\n",
            "wall_100=Wall(178,328,10,178,329,10,140,0)\n",
            "wall_11=Wall(178,329,10,188,329,10,140,0)\n",
            "wall_12=Wall(188,329,10,188,340,10,140,0)\n",
            "wall_13=Wall(178,340,10,188,340,10,140,0)\n",
            "wall_14=Wall(178,340,10,178,343,10,140,0)\n",
            "wall_15=Wall(178,343,10,198,343,10,140,0)\n",
            "door_0=Door(wall_15,184,343,56,48,115)\n",
            "bbox_0=Bbox(chair,87,119,29,560,38,37,61)\n",
            "bbox_1=Bbox(chair,132,119,29,400,38,37,61)\n",
            "bbox_2=Bbox(chair,99,158,29,400,38,37,61)\n",
            "bbox_3=Bbox(chair,111,158,29,560,38,37,61)\n",
            "bbox_4=Bbox(tv,130,158,69,560,75,6,44)\n",
            "bbox_5=Bbox(chair,135,159,29,560,38,37,61)\n",
            "bbox_6=Bbox(chair,101,170,29,400,38,37,61)\n",
            "bbox_7=Bbox(chair,111,170,29,400,38,37,61)\n",
            "bbox_8=Bbox(chair,132,170,29,400,38,37,61)\\nDone!\n",
            "\\n✓ Layout generated\n"
          ]
        }
      ],
      "source": [
        "# Cell 7: Generate Layout\n",
        "layout = generate_layout(\n",
        "    model, input_pcd, tokenizer, code_template_file,\n",
        "    top_k=top_k, top_p=top_p, temperature=temperature,\n",
        "    num_beams=num_beams, seed=seed, detect_type=detect_type,\n",
        "    categories=categories\n",
        ")\n",
        "\n",
        "layout.translate(min_extent)\n",
        "print(f\"\\\\n✓ Layout generated\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Saved to: /mnt/cluster/workspaces/jinjingxu/proj/vlm/SpatialLM/outputs/scene40753679.txt\n",
            "\\n--- Preview (500 chars) ---\n",
            "wall_0=Wall(4.272488516569138,-3.299999952316284,-1.5505512356758118,4.897488516569138,-3.299999952316284,-1.5505512356758118,2.8000000000000003,0.0)\n",
            "wall_1=Wall(4.272488516569138,-3.299999952316284,-1.5505512356758118,3.8224885165691376,-3.1499999523162843,-1.5505512356758118,2.8000000000000003,0.0)\n",
            "wall_2=Wall(4.897488516569138,-3.299999952316284,-1.5505512356758118,4.897488516569138,-1.4249999523162842,-1.5505512356758118,2.8000000000000003,0.0)\n",
            "wall_3=Wall(3.8224885165691376,-3.1499999523162\n",
            "... +16851 chars\n"
          ]
        }
      ],
      "source": [
        "# Cell 8: Save Output\n",
        "pred_language_string = layout.to_language_string()\n",
        "\n",
        "if os.path.splitext(output_path)[-1]:\n",
        "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
        "    with open(output_path, \"w\") as f:\n",
        "        f.write(pred_language_string)\n",
        "    print(f\"✓ Saved to: {output_path}\")\n",
        "else:\n",
        "    output_filename = os.path.basename(point_cloud_file).replace(\".ply\", \".txt\")\n",
        "    os.makedirs(output_path, exist_ok=True)\n",
        "    output_file = os.path.join(output_path, output_filename)\n",
        "    with open(output_file, \"w\") as f:\n",
        "        f.write(pred_language_string)\n",
        "    print(f\"✓ Saved to: {output_file}\")\n",
        "\n",
        "print(\"\\\\n--- Preview (500 chars) ---\")\n",
        "print(pred_language_string[:500])\n",
        "if len(pred_language_string) > 500:\n",
        "    print(f\"... +{len(pred_language_string)-500} chars\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optional: Batch Processing\n",
        "Uncomment the cell below to process all files in batch mode."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 9: Batch Process All Files (Optional)\n",
        "# Uncomment to run batch processing\n",
        "\n",
        "# for point_cloud_file in tqdm(point_cloud_files):\n",
        "#     point_cloud = load_o3d_pcd(str(point_cloud_file))\n",
        "#     grid_size = Layout.get_grid_size(num_bins)\n",
        "#     if not no_cleanup:\n",
        "#         point_cloud = cleanup_pcd(point_cloud, voxel_size=grid_size)\n",
        "#     points, colors = get_points_and_colors(point_cloud)\n",
        "#     min_extent = np.min(points, axis=0)\n",
        "#     input_pcd = preprocess_point_cloud(points, colors, grid_size, num_bins)\n",
        "#     layout = generate_layout(model, input_pcd, tokenizer, code_template_file,\n",
        "#                              top_k=top_k, top_p=top_p, temperature=temperature,\n",
        "#                              num_beams=num_beams, seed=seed, detect_type=detect_type,\n",
        "#                              categories=categories)\n",
        "#     layout.translate(min_extent)\n",
        "#     pred_language_string = layout.to_language_string()\n",
        "#     if os.path.splitext(output_path)[-1]:\n",
        "#         with open(output_path, \"w\") as f:\n",
        "#             f.write(pred_language_string)\n",
        "#     else:\n",
        "#         output_filename = os.path.basename(point_cloud_file).replace(\".ply\", \".txt\")\n",
        "#         os.makedirs(output_path, exist_ok=True)\n",
        "#         with open(os.path.join(output_path, output_filename), \"w\") as f:\n",
        "#             f.write(pred_language_string)\n",
        "# print(f\"✓ Batch complete: {len(point_cloud_files)} files\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "spatiallm",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
