{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SpatialLM Inference Notebook\n",
        "This notebook breaks down the inference.py workflow into interactive cells."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Imports loaded\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: Imports and Constants\n",
        "import os\n",
        "import sys\n",
        "import glob\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from threading import Thread\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from transformers import TextIteratorStreamer, set_seed\n",
        "\n",
        "# Add project root to path\n",
        "PROJECT_ROOT = Path(\"/home/jixu233b/Projects/VLM_3D/SpatialLM\")\n",
        "sys.path.insert(0, str(PROJECT_ROOT))\n",
        "\n",
        "from spatiallm import Layout\n",
        "from spatiallm.pcd import load_o3d_pcd, get_points_and_colors, cleanup_pcd, Compose\n",
        "\n",
        "DETECT_TYPE_PROMPT = {\n",
        "    \"all\": \"Detect walls, doors, windows, boxes.\",\n",
        "    \"arch\": \"Detect walls, doors, windows.\",\n",
        "    \"object\": \"Detect boxes.\",\n",
        "}\n",
        "\n",
        "print(\"✓ Imports loaded\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Helper functions defined\n"
          ]
        }
      ],
      "source": [
        "# Cell 2: Define Helper Functions\n",
        "\n",
        "def preprocess_point_cloud(points, colors, grid_size, num_bins):\n",
        "    \"\"\"Preprocess point cloud into tensor features.\"\"\"\n",
        "    transform = Compose([\n",
        "        dict(type=\"PositiveShift\"),\n",
        "        dict(type=\"NormalizeColor\"),\n",
        "        dict(\n",
        "            type=\"GridSample\",\n",
        "            grid_size=grid_size,\n",
        "            hash_type=\"fnv\",\n",
        "            mode=\"test\",\n",
        "            keys=(\"coord\", \"color\"),\n",
        "            return_grid_coord=True,\n",
        "            max_grid_coord=num_bins,\n",
        "        ),\n",
        "    ])\n",
        "    point_cloud = transform({\n",
        "        \"name\": \"pcd\",\n",
        "        \"coord\": points.copy(),\n",
        "        \"color\": colors.copy(),\n",
        "    })\n",
        "    coord = point_cloud[\"grid_coord\"]\n",
        "    xyz = point_cloud[\"coord\"]\n",
        "    rgb = point_cloud[\"color\"]\n",
        "    point_cloud = np.concatenate([coord, xyz, rgb], axis=1)\n",
        "    return torch.as_tensor(np.stack([point_cloud], axis=0))\n",
        "\n",
        "\n",
        "def generate_layout(model, point_cloud, tokenizer, code_template_file, \n",
        "                    top_k=10, top_p=0.95, temperature=0.6, num_beams=1,\n",
        "                    seed=-1, max_new_tokens=4096, detect_type=\"all\", categories=[]):\n",
        "    \"\"\"Generate layout from point cloud using the model.\"\"\"\n",
        "    if seed >= 0:\n",
        "        set_seed(seed)\n",
        "    \n",
        "    with open(code_template_file, \"r\") as f:\n",
        "        code_template = f.read()\n",
        "    \n",
        "    task_prompt = DETECT_TYPE_PROMPT[detect_type]\n",
        "    if detect_type != \"arch\" and categories:\n",
        "        task_prompt = task_prompt.replace(\"boxes\", \", \".join(categories))\n",
        "    print(\"Task prompt:\", task_prompt)\n",
        "    \n",
        "    prompt = f\"<|point_start|><|point_pad|><|point_end|>{task_prompt} The reference code is as followed: {code_template}\"\n",
        "    \n",
        "    if model.config.model_type == \"spatiallm_qwen\":\n",
        "        conversation = [\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt},\n",
        "        ]\n",
        "    else:\n",
        "        conversation = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    \n",
        "    input_ids = tokenizer.apply_chat_template(conversation, add_generation_prompt=True, return_tensors=\"pt\")\n",
        "    input_ids = input_ids.to(model.device)\n",
        "    \n",
        "    streamer = TextIteratorStreamer(tokenizer, timeout=20.0, skip_prompt=True, skip_special_tokens=True)\n",
        "    \n",
        "    generate_kwargs = dict(\n",
        "        {\"input_ids\": input_ids, \"point_clouds\": point_cloud},\n",
        "        streamer=streamer,\n",
        "        max_new_tokens=max_new_tokens,\n",
        "        do_sample=True,\n",
        "        use_cache=True,\n",
        "        temperature=temperature,\n",
        "        top_p=top_p,\n",
        "        top_k=top_k,\n",
        "        num_beams=num_beams,\n",
        "    )\n",
        "    t = Thread(target=model.generate, kwargs=generate_kwargs)\n",
        "    t.start()\n",
        "    \n",
        "    print(\"Generating layout...\\\\n\")\n",
        "    generate_texts = []\n",
        "    for text in streamer:\n",
        "        generate_texts.append(text)\n",
        "        print(text, end=\"\", flush=True)\n",
        "    print(\"\\\\nDone!\")\n",
        "    \n",
        "    layout_str = \"\".join(generate_texts)\n",
        "    layout = Layout(layout_str)\n",
        "    layout.undiscretize_and_unnormalize(num_bins=model.config.point_config[\"num_bins\"])\n",
        "    return layout\n",
        "\n",
        "print(\"✓ Helper functions defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Parameters configured\n"
          ]
        }
      ],
      "source": [
        "# Cell 3: Set Parameters\n",
        "DATA_ROOT = Path(\"/data/horse/ws/jixu233b-metadata_ws/datasets/arkitscenes-spatiallm/\")\n",
        "\n",
        "# Input/Output paths\n",
        "point_cloud_path = DATA_ROOT / \"pcd/40753679.ply\"\n",
        "output_path = PROJECT_ROOT / \"outputs/scene40753679.txt\"\n",
        "\n",
        "# Model configuration\n",
        "model_path = \"manycore-research/SpatialLM1.1-Qwen-0.5B\"\n",
        "\n",
        "# Inference parameters\n",
        "detect_type = \"all\"\n",
        "categories = []\n",
        "code_template_file = str(PROJECT_ROOT / \"code_template.txt\")\n",
        "\n",
        "# Generation parameters\n",
        "top_k = 10\n",
        "top_p = 0.95\n",
        "temperature = 0.6\n",
        "num_beams = 1\n",
        "seed = -1\n",
        "max_new_tokens = 4096\n",
        "inference_dtype = \"bfloat16\"\n",
        "no_cleanup = False\n",
        "\n",
        "# Optional: JSON file to filter specific samples\n",
        "json_file = None\n",
        "\n",
        "print(\"✓ Parameters configured\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading model from manycore-research/SpatialLM1.1-Qwen-0.5B...\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "No CUDA GPUs are available",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m tokenizer = AutoTokenizer.from_pretrained(model_path)\n\u001b[32m      4\u001b[39m model = AutoModelForCausalLM.from_pretrained(model_path, torch_dtype=\u001b[38;5;28mgetattr\u001b[39m(torch, inference_dtype))\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcuda\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m model.set_point_backbone_dtype(torch.float32)\n\u001b[32m      7\u001b[39m model.eval()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/data/horse/ws/jixu233b-3d_ws/envs/spatiallm/lib/python3.11/site-packages/transformers/modeling_utils.py:3157\u001b[39m, in \u001b[36mPreTrainedModel.to\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   3152\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m dtype_present_in_args:\n\u001b[32m   3153\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   3154\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   3155\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m `dtype` by passing the correct `torch_dtype` argument.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   3156\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m3157\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/data/horse/ws/jixu233b-3d_ws/envs/spatiallm/lib/python3.11/site-packages/torch/nn/modules/module.py:1152\u001b[39m, in \u001b[36mModule.to\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1148\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m t.to(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t.is_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t.is_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1149\u001b[39m                     non_blocking, memory_format=convert_to_format)\n\u001b[32m   1150\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m t.to(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t.is_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t.is_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[32m-> \u001b[39m\u001b[32m1152\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/data/horse/ws/jixu233b-3d_ws/envs/spatiallm/lib/python3.11/site-packages/torch/nn/modules/module.py:802\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    800\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    801\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m802\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    804\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[32m    805\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[32m    806\u001b[39m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[32m    807\u001b[39m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    812\u001b[39m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[32m    813\u001b[39m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/data/horse/ws/jixu233b-3d_ws/envs/spatiallm/lib/python3.11/site-packages/torch/nn/modules/module.py:802\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    800\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    801\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m802\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    804\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[32m    805\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[32m    806\u001b[39m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[32m    807\u001b[39m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    812\u001b[39m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[32m    813\u001b[39m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/data/horse/ws/jixu233b-3d_ws/envs/spatiallm/lib/python3.11/site-packages/torch/nn/modules/module.py:825\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    821\u001b[39m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[32m    822\u001b[39m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[32m    823\u001b[39m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[32m    824\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m825\u001b[39m     param_applied = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    826\u001b[39m should_use_set_data = compute_should_use_set_data(param, param_applied)\n\u001b[32m    827\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/data/horse/ws/jixu233b-3d_ws/envs/spatiallm/lib/python3.11/site-packages/torch/nn/modules/module.py:1150\u001b[39m, in \u001b[36mModule.to.<locals>.convert\u001b[39m\u001b[34m(t)\u001b[39m\n\u001b[32m   1147\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t.dim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[32m4\u001b[39m, \u001b[32m5\u001b[39m):\n\u001b[32m   1148\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m t.to(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t.is_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t.is_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1149\u001b[39m                 non_blocking, memory_format=convert_to_format)\n\u001b[32m-> \u001b[39m\u001b[32m1150\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/data/horse/ws/jixu233b-3d_ws/envs/spatiallm/lib/python3.11/site-packages/torch/cuda/__init__.py:302\u001b[39m, in \u001b[36m_lazy_init\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    300\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mCUDA_MODULE_LOADING\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os.environ:\n\u001b[32m    301\u001b[39m     os.environ[\u001b[33m\"\u001b[39m\u001b[33mCUDA_MODULE_LOADING\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mLAZY\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m302\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    303\u001b[39m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[32m    304\u001b[39m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[32m    305\u001b[39m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[32m    306\u001b[39m _tls.is_initializing = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "\u001b[31mRuntimeError\u001b[39m: No CUDA GPUs are available"
          ]
        }
      ],
      "source": [
        "# Cell 4: Load Model and Tokenizer\n",
        "print(f\"Loading model from {model_path}...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_path, torch_dtype=getattr(torch, inference_dtype))\n",
        "model.to(\"cuda\")\n",
        "model.set_point_backbone_dtype(torch.float32)\n",
        "model.eval()\n",
        "\n",
        "num_bins = model.config.point_config[\"num_bins\"]\n",
        "\n",
        "print(f\"✓ Model loaded\")\n",
        "print(f\"  - Type: {model.config.model_type}\")\n",
        "print(f\"  - Bins: {num_bins}\")\n",
        "print(f\"  - Device: {model.device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 5: Discover Point Cloud Files\n",
        "if os.path.isfile(point_cloud_path):\n",
        "    point_cloud_files = [point_cloud_path]\n",
        "else:\n",
        "    if json_file is not None:\n",
        "        print(f\"Loading samples from JSON: {json_file}\")\n",
        "        with open(json_file, \"r\") as f:\n",
        "            json_data = json.load(f)\n",
        "        \n",
        "        point_cloud_files = []\n",
        "        for item in json_data:\n",
        "            pcd_files = []\n",
        "            if isinstance(item, str):\n",
        "                pcd_files = [item]\n",
        "            elif isinstance(item, dict):\n",
        "                value = (item.get(\"point_clouds\") or item.get(\"point_cloud\") or \n",
        "                        item.get(\"file_name\") or item.get(\"pcd_file\") or \n",
        "                        item.get(\"scene_id\") or item.get(\"id\"))\n",
        "                pcd_files = value if isinstance(value, list) else [value] if value else []\n",
        "            \n",
        "            for pcd_file in pcd_files:\n",
        "                pcd_file = pcd_file.replace(\"pcd/\", \"\")\n",
        "                if not pcd_file.endswith(\".ply\"):\n",
        "                    pcd_file = f\"{pcd_file}.ply\"\n",
        "                \n",
        "                full_path = os.path.join(point_cloud_path, pcd_file)\n",
        "                if os.path.exists(full_path):\n",
        "                    point_cloud_files.append(full_path)\n",
        "                else:\n",
        "                    print(f\"Warning: Not found: {full_path}\")\n",
        "        print(f\"Found {len(point_cloud_files)} samples from JSON\")\n",
        "    else:\n",
        "        point_cloud_files = glob.glob(os.path.join(point_cloud_path, \"*.ply\"))\n",
        "\n",
        "print(f\"✓ Found {len(point_cloud_files)} file(s)\")\n",
        "for i, f in enumerate(point_cloud_files[:5]):\n",
        "    print(f\"  [{i+1}] {os.path.basename(f)}\")\n",
        "if len(point_cloud_files) > 5:\n",
        "    print(f\"  ... +{len(point_cloud_files)-5} more\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 6: Load and Preprocess Point Cloud\n",
        "current_file_idx = 0\n",
        "point_cloud_file = point_cloud_files[current_file_idx]\n",
        "print(f\"Processing: {os.path.basename(point_cloud_file)}\")\n",
        "\n",
        "point_cloud = load_o3d_pcd(point_cloud_file)\n",
        "grid_size = Layout.get_grid_size(num_bins)\n",
        "\n",
        "if not no_cleanup:\n",
        "    point_cloud = cleanup_pcd(point_cloud, voxel_size=grid_size)\n",
        "\n",
        "points, colors = get_points_and_colors(point_cloud)\n",
        "min_extent = np.min(points, axis=0)\n",
        "\n",
        "print(f\"✓ Point cloud loaded\")\n",
        "print(f\"  - Points: {len(points)}\")\n",
        "print(f\"  - Range: {np.min(points, axis=0)} to {np.max(points, axis=0)}\")\n",
        "print(f\"  - Grid: {grid_size}\")\n",
        "\n",
        "input_pcd = preprocess_point_cloud(points, colors, grid_size, num_bins)\n",
        "print(f\"✓ Preprocessed: {input_pcd.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 7: Generate Layout\n",
        "layout = generate_layout(\n",
        "    model, input_pcd, tokenizer, code_template_file,\n",
        "    top_k=top_k, top_p=top_p, temperature=temperature,\n",
        "    num_beams=num_beams, seed=seed, detect_type=detect_type,\n",
        "    categories=categories\n",
        ")\n",
        "\n",
        "layout.translate(min_extent)\n",
        "print(f\"\\\\n✓ Layout generated\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 8: Save Output\n",
        "pred_language_string = layout.to_language_string()\n",
        "\n",
        "if os.path.splitext(output_path)[-1]:\n",
        "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
        "    with open(output_path, \"w\") as f:\n",
        "        f.write(pred_language_string)\n",
        "    print(f\"✓ Saved to: {output_path}\")\n",
        "else:\n",
        "    output_filename = os.path.basename(point_cloud_file).replace(\".ply\", \".txt\")\n",
        "    os.makedirs(output_path, exist_ok=True)\n",
        "    output_file = os.path.join(output_path, output_filename)\n",
        "    with open(output_file, \"w\") as f:\n",
        "        f.write(pred_language_string)\n",
        "    print(f\"✓ Saved to: {output_file}\")\n",
        "\n",
        "print(\"\\\\n--- Preview (500 chars) ---\")\n",
        "print(pred_language_string[:500])\n",
        "if len(pred_language_string) > 500:\n",
        "    print(f\"... +{len(pred_language_string)-500} chars\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optional: Batch Processing\n",
        "Uncomment the cell below to process all files in batch mode."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 9: Batch Process All Files (Optional)\n",
        "# Uncomment to run batch processing\n",
        "\n",
        "# for point_cloud_file in tqdm(point_cloud_files):\n",
        "#     point_cloud = load_o3d_pcd(point_cloud_file)\n",
        "#     grid_size = Layout.get_grid_size(num_bins)\n",
        "#     if not no_cleanup:\n",
        "#         point_cloud = cleanup_pcd(point_cloud, voxel_size=grid_size)\n",
        "#     points, colors = get_points_and_colors(point_cloud)\n",
        "#     min_extent = np.min(points, axis=0)\n",
        "#     input_pcd = preprocess_point_cloud(points, colors, grid_size, num_bins)\n",
        "#     layout = generate_layout(model, input_pcd, tokenizer, code_template_file,\n",
        "#                              top_k=top_k, top_p=top_p, temperature=temperature,\n",
        "#                              num_beams=num_beams, seed=seed, detect_type=detect_type,\n",
        "#                              categories=categories)\n",
        "#     layout.translate(min_extent)\n",
        "#     pred_language_string = layout.to_language_string()\n",
        "#     if os.path.splitext(output_path)[-1]:\n",
        "#         with open(output_path, \"w\") as f:\n",
        "#             f.write(pred_language_string)\n",
        "#     else:\n",
        "#         output_filename = os.path.basename(point_cloud_file).replace(\".ply\", \".txt\")\n",
        "#         os.makedirs(output_path, exist_ok=True)\n",
        "#         with open(os.path.join(output_path, output_filename), \"w\") as f:\n",
        "#             f.write(pred_language_string)\n",
        "# print(f\"✓ Batch complete: {len(point_cloud_files)} files\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
