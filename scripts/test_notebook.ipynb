{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SpatialLM Inference Notebook\n",
        "\n",
        "This notebook breaks down the inference.py workflow into interactive cells.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸŽ¯ Quick Configuration\n",
        "\n",
        "### Environment Variables (Set in Cell 2)\n",
        "\n",
        "**`SPATIALLM_VERBOSE`** - Controls debug printouts:\n",
        "- `\"0\"` (default): Clean output, no debug info\n",
        "- `\"1\"`: Show detailed checkpoints for 3D PE debugging\n",
        "\n",
        "**Important**: Must be set in **Cell 2** BEFORE importing spatiallm modules!\n",
        "\n",
        "### Model Parameters (Set in Cell 4)\n",
        "\n",
        "**`VLM_PE`** - Positional encoding type for point cloud tokens:\n",
        "- `None` (default): Standard 1D RoPE\n",
        "- `\"CCA_2DProj\"`: Concentric Causal Attention with 2D projection\n",
        "- `\"3D_RoPE\"`: 3D Rotary Position Embedding\n",
        "- `\"3D_Sinusoidal\"`: 3D Sinusoidal Position Embedding\n",
        "\n",
        "**`PCD_PE_Merge_Rule`** - 3D PE dimension allocation (only for `3D_RoPE` or `3D_Sinusoidal`):\n",
        "- `\"3D_only\"` (default): Point tokens use only 3D spatial PE\n",
        "- `\"3D_with_1D\"`: Point tokens use both 3D spatial + 1D sequence PE\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ“‹ Execution Order\n",
        "\n",
        "1. Run **Cell 1**: Auto-reload setup\n",
        "2. Run **Cell 2**: Set environment variables + imports âš ï¸ **Set SPATIALLM_VERBOSE here**\n",
        "3. Run **Cell 3**: Helper functions\n",
        "4. Run **Cell 4**: Set inference parameters âš ï¸ **Set VLM_PE and PCD_PE_Merge_Rule here**\n",
        "5. Run remaining cells in order..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 1: Environment Variables (SET FIRST, BEFORE ANY IMPORTS!)\n",
        "import os\n",
        "\n",
        "# === IMPORTANT: Set these BEFORE importing spatiallm modules ===\n",
        "# Verbose debug flag (controls checkpoint printouts)\n",
        "os.environ[\"SPATIALLM_VERBOSE\"] = \"0\"  # Set to \"0\" or \"1\" \n",
        "\n",
        "print(f\"âœ“ SPATIALLM_VERBOSE = {os.environ.get('SPATIALLM_VERBOSE')}\")\n",
        "\n",
        "# Now import other modules\n",
        "import sys\n",
        "import glob\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from threading import Thread\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from transformers import TextIteratorStreamer, set_seed\n",
        "\n",
        "# Add project root to path\n",
        "PROJ_PATH = \"/mnt/cluster/workspaces/jinjingxu/proj/vlm/SpatialLM\"\n",
        "DATA_ROOT = '/data/horse/ws/jixu233b-metadata_ws/datasets/arkitscenes-spatiallm/'\n",
        "DATA_ROOT = '/mnt/nct-zfs/TCO-All/SharedDatasets/arkitscenes-spatiallm/'\n",
        "\n",
        "PROJECT_ROOT = Path(PROJ_PATH)\n",
        "sys.path.insert(0, str(PROJECT_ROOT))\n",
        "\n",
        "from spatiallm import Layout\n",
        "from spatiallm.pcd import load_o3d_pcd, get_points_and_colors, cleanup_pcd, Compose\n",
        "\n",
        "DETECT_TYPE_PROMPT = {\n",
        "    \"all\": \"Detect walls, doors, windows, boxes.\",\n",
        "    \"arch\": \"Detect walls, doors, windows.\",\n",
        "    \"object\": \"Detect boxes.\",\n",
        "}\n",
        "\n",
        "print(\"âœ“ Imports loaded\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 2: Define Helper Functions\n",
        "\n",
        "def preprocess_point_cloud(points, colors, grid_size, num_bins):\n",
        "    \"\"\"Preprocess point cloud into tensor features.\"\"\"\n",
        "    transform = Compose([\n",
        "        dict(type=\"PositiveShift\"),\n",
        "        dict(type=\"NormalizeColor\"),\n",
        "        dict(\n",
        "            type=\"GridSample\",\n",
        "            grid_size=grid_size,\n",
        "            hash_type=\"fnv\",\n",
        "            mode=\"test\",\n",
        "            keys=(\"coord\", \"color\"),\n",
        "            return_grid_coord=True,\n",
        "            max_grid_coord=num_bins,\n",
        "        ),\n",
        "    ])\n",
        "    point_cloud = transform({\n",
        "        \"name\": \"pcd\",\n",
        "        \"coord\": points.copy(),\n",
        "        \"color\": colors.copy(),\n",
        "    })\n",
        "    coord = point_cloud[\"grid_coord\"]\n",
        "    xyz = point_cloud[\"coord\"]\n",
        "    rgb = point_cloud[\"color\"]\n",
        "    point_cloud = np.concatenate([coord, xyz, rgb], axis=1)\n",
        "    return torch.as_tensor(np.stack([point_cloud], axis=0))\n",
        "\n",
        "\n",
        "def generate_layout(model, point_cloud, tokenizer, code_template_file, \n",
        "                    top_k=10, top_p=0.95, temperature=0.6, num_beams=1,\n",
        "                    seed=-1, max_new_tokens=4096, detect_type=\"all\", categories=[]):\n",
        "    \"\"\"Generate layout from point cloud using the model.\"\"\"\n",
        "    if seed >= 0:\n",
        "        set_seed(seed)\n",
        "    \n",
        "    with open(code_template_file, \"r\") as f:\n",
        "        code_template = f.read()\n",
        "    \n",
        "    task_prompt = DETECT_TYPE_PROMPT[detect_type]\n",
        "    if detect_type != \"arch\" and categories:\n",
        "        task_prompt = task_prompt.replace(\"boxes\", \", \".join(categories))\n",
        "    print(\"Task prompt:\", task_prompt)\n",
        "    \n",
        "    prompt = f\"<|point_start|><|point_pad|><|point_end|>{task_prompt} The reference code is as followed: {code_template}\"\n",
        "    \n",
        "    if model.config.model_type == \"spatiallm_qwen\":\n",
        "        conversation = [\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt},\n",
        "        ]\n",
        "    else:\n",
        "        conversation = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    \n",
        "    input_ids = tokenizer.apply_chat_template(conversation, add_generation_prompt=True, return_tensors=\"pt\")\n",
        "    input_ids = input_ids.to(model.device)\n",
        "    \n",
        "    streamer = TextIteratorStreamer(tokenizer, timeout=20.0, skip_prompt=True, skip_special_tokens=True)\n",
        "    \n",
        "    generate_kwargs = dict(\n",
        "        {\"input_ids\": input_ids, \"point_clouds\": point_cloud},\n",
        "        streamer=streamer,\n",
        "        max_new_tokens=max_new_tokens,\n",
        "        do_sample=True,\n",
        "        use_cache=True,\n",
        "        temperature=temperature,\n",
        "        top_p=top_p,\n",
        "        top_k=top_k,\n",
        "        num_beams=num_beams,\n",
        "    )\n",
        "    t = Thread(target=model.generate, kwargs=generate_kwargs)\n",
        "    t.start()\n",
        "    \n",
        "    print(\"Generating layout...\\\\n\")\n",
        "    generate_texts = []\n",
        "    for text in streamer:\n",
        "        generate_texts.append(text)\n",
        "        print(text, end=\"\", flush=True)\n",
        "    print(\"\\\\nDone!\")\n",
        "    \n",
        "    layout_str = \"\".join(generate_texts)\n",
        "    layout = Layout(layout_str)\n",
        "    layout.undiscretize_and_unnormalize(num_bins=model.config.point_config[\"num_bins\"])\n",
        "    return layout\n",
        "\n",
        "print(\"âœ“ Helper functions defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 3: Set Parameters\n",
        "DATA_ROOT = Path(DATA_ROOT)\n",
        "\n",
        "# Input/Output paths\n",
        "point_cloud_path = DATA_ROOT / \"pcd/40753679.ply\"\n",
        "output_path = PROJECT_ROOT / \"outputs/scene40753679.txt\"\n",
        "\n",
        "# Model configuration\n",
        "model_path = \"manycore-research/SpatialLM1.1-Qwen-0.5B\"\n",
        "disable_flash_attn = True  # Set to True for V100/older GPUs, False for A100+\n",
        "vlm_pe = '1D_RoPE'  # Options: "1D_RoPE" (standard, default), \"CCA_2DProj\", \"3D_RoPE\", \"3D_Sinusoidal\"\n",
        "pcd_pe_merge_rule = '3D_with_1D'  # Options: \"3D_only\", \"3D_with_1D\" (only for 3D_RoPE/3D_Sinusoidal)\n",
        "\n",
        "# Inference parameters\n",
        "detect_type = \"all\"\n",
        "categories = []\n",
        "code_template_file = str(PROJECT_ROOT / \"code_template.txt\")\n",
        "\n",
        "# Generation parameters\n",
        "top_k = 10\n",
        "top_p = 0.95\n",
        "temperature = 0.6\n",
        "num_beams = 1\n",
        "seed = -1\n",
        "max_new_tokens = 4096\n",
        "inference_dtype = \"bfloat16\"\n",
        "no_cleanup = False\n",
        "\n",
        "# Optional: JSON file to filter specific samples\n",
        "json_file = None\n",
        "\n",
        "print(\"âœ“ Parameters configured\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 4: Diagnostic - Check CUDA Status\n",
        "import torch\n",
        "import sys\n",
        "\n",
        "print(\"=== CUDA Diagnostic ===\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "print(f\"CUDA version: {torch.version.cuda}\")\n",
        "print(f\"CUDA device count: {torch.cuda.device_count()}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"Current CUDA device: {torch.cuda.current_device()}\")\n",
        "    print(f\"Device name: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"Device capability: {torch.cuda.get_device_capability(0)}\")\n",
        "\n",
        "print(f\"\\nPython executable: {sys.executable}\")\n",
        "print(f\"Python version: {sys.version.split()[0]}\")\n",
        "\n",
        "# Try to initialize CUDA explicitly\n",
        "try:\n",
        "    torch.cuda.init()\n",
        "    print(\"\\nâœ“ CUDA initialization successful\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nâœ— CUDA initialization failed: {e}\")\n",
        "\n",
        "# Try to create a small tensor on CUDA\n",
        "try:\n",
        "    test_tensor = torch.zeros(1).cuda()\n",
        "    print(f\"âœ“ Test tensor created on CUDA: {test_tensor.device}\")\n",
        "    del test_tensor\n",
        "except Exception as e:\n",
        "    print(f\"âœ— Failed to create tensor on CUDA: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 4: Load Model and Tokenizer\n",
        "print(f\"Loading model from {model_path}...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "\n",
        "# Check if we need to modify config\n",
        "if disable_flash_attn or vlm_pe is not None:\n",
        "    from transformers import AutoConfig\n",
        "    config = AutoConfig.from_pretrained(model_path, trust_remote_code=True)\n",
        "    # Disable flash attention if requested\n",
        "    if disable_flash_attn:\n",
        "        if hasattr(config, 'point_config'):\n",
        "            config.point_config['enable_flash'] = False\n",
        "    # Set vlm_pe if specified\n",
        "    if vlm_pe is not None:\n",
        "        config.vlm_pe = vlm_pe\n",
        "    # Set pcd_pe_merge_rule (for 3D_RoPE and 3D_Sinusoidal)\n",
        "    config.pcd_pe_merge_rule = pcd_pe_merge_rule\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_path, \n",
        "        config=config,\n",
        "        torch_dtype=getattr(torch, inference_dtype)\n",
        "    )\n",
        "else:\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_path,\n",
        "        torch_dtype=getattr(torch, inference_dtype)\n",
        "    )\n",
        "\n",
        "model.to(\"cuda\")\n",
        "model.set_point_backbone_dtype(torch.float32)\n",
        "model.eval()\n",
        "\n",
        "num_bins = model.config.point_config[\"num_bins\"]\n",
        "\n",
        "print(f\"âœ“ Model loaded\")\n",
        "print(f\"  - Type: {model.config.model_type}\")\n",
        "print(f\"  - Bins: {num_bins}\")\n",
        "print(f\"  - Device: {model.device}\")\n",
        "print(f\"  - FlashAttention: {not disable_flash_attn}\")\n",
        "print(f\"  - vlm_pe: {vlm_pe if vlm_pe is not None else 'None (standard RoPE)'}\")\n",
        "print(f\"  - pcd_pe_merge_rule: {pcd_pe_merge_rule}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('Pointcloud path: ', point_cloud_path)\n",
        "# Cell 5: Discover Point Cloud Files\n",
        "if os.path.isfile(point_cloud_path):\n",
        "    point_cloud_files = [point_cloud_path]\n",
        "else:\n",
        "    if json_file is not None:\n",
        "        print(f\"Loading samples from JSON: {json_file}\")\n",
        "        with open(json_file, \"r\") as f:\n",
        "            json_data = json.load(f)\n",
        "        \n",
        "        point_cloud_files = []\n",
        "        for item in json_data:\n",
        "            pcd_files = []\n",
        "            if isinstance(item, str):\n",
        "                pcd_files = [item]\n",
        "            elif isinstance(item, dict):\n",
        "                value = (item.get(\"point_clouds\") or item.get(\"point_cloud\") or \n",
        "                        item.get(\"file_name\") or item.get(\"pcd_file\") or \n",
        "                        item.get(\"scene_id\") or item.get(\"id\"))\n",
        "                pcd_files = value if isinstance(value, list) else [value] if value else []\n",
        "            \n",
        "            for pcd_file in pcd_files:\n",
        "                pcd_file = pcd_file.replace(\"pcd/\", \"\")\n",
        "                if not pcd_file.endswith(\".ply\"):\n",
        "                    pcd_file = f\"{pcd_file}.ply\"\n",
        "                \n",
        "                full_path = os.path.join(point_cloud_path, pcd_file)\n",
        "                if os.path.exists(full_path):\n",
        "                    point_cloud_files.append(full_path)\n",
        "                else:\n",
        "                    print(f\"Warning: Not found: {full_path}\")\n",
        "        print(f\"Found {len(point_cloud_files)} samples from JSON\")\n",
        "    else:\n",
        "        point_cloud_files = glob.glob(os.path.join(point_cloud_path, \"*.ply\"))\n",
        "\n",
        "print(f\"âœ“ Found {len(point_cloud_files)} file(s)\")\n",
        "for i, f in enumerate(point_cloud_files[:5]):\n",
        "    print(f\"  [{i+1}] {os.path.basename(f)}\")\n",
        "if len(point_cloud_files) > 5:\n",
        "    print(f\"  ... +{len(point_cloud_files)-5} more\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 6: Load and Preprocess Point Cloud\n",
        "current_file_idx = 0\n",
        "point_cloud_file = point_cloud_files[current_file_idx]\n",
        "print(f\"Processing: {os.path.basename(point_cloud_file)}\")\n",
        "\n",
        "point_cloud = load_o3d_pcd(str(point_cloud_file))\n",
        "grid_size = Layout.get_grid_size(num_bins)\n",
        "\n",
        "if not no_cleanup:\n",
        "    point_cloud = cleanup_pcd(point_cloud, voxel_size=grid_size)\n",
        "\n",
        "points, colors = get_points_and_colors(point_cloud)\n",
        "min_extent = np.min(points, axis=0)\n",
        "\n",
        "print(f\"âœ“ Point cloud loaded\")\n",
        "print(f\"  - Points: {len(points)}\")\n",
        "print(f\"  - Range: {np.min(points, axis=0)} to {np.max(points, axis=0)}\")\n",
        "print(f\"  - Grid: {grid_size}\")\n",
        "\n",
        "input_pcd = preprocess_point_cloud(points, colors, grid_size, num_bins)\n",
        "print(f\"âœ“ Preprocessed: {input_pcd.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 7: Generate Layout\n",
        "layout = generate_layout(\n",
        "    model, input_pcd, tokenizer, code_template_file,\n",
        "    top_k=top_k, top_p=top_p, temperature=temperature,\n",
        "    num_beams=num_beams, seed=seed, detect_type=detect_type,\n",
        "    categories=categories\n",
        ")\n",
        "\n",
        "layout.translate(min_extent)\n",
        "print(f\"\\\\nâœ“ Layout generated\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 8: Save Output\n",
        "pred_language_string = layout.to_language_string()\n",
        "\n",
        "if os.path.splitext(output_path)[-1]:\n",
        "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
        "    with open(output_path, \"w\") as f:\n",
        "        f.write(pred_language_string)\n",
        "    print(f\"âœ“ Saved to: {output_path}\")\n",
        "else:\n",
        "    output_filename = os.path.basename(point_cloud_file).replace(\".ply\", \".txt\")\n",
        "    os.makedirs(output_path, exist_ok=True)\n",
        "    output_file = os.path.join(output_path, output_filename)\n",
        "    with open(output_file, \"w\") as f:\n",
        "        f.write(pred_language_string)\n",
        "    print(f\"âœ“ Saved to: {output_file}\")\n",
        "\n",
        "print(\"\\\\n--- Preview (500 chars) ---\")\n",
        "print(pred_language_string[:500])\n",
        "if len(pred_language_string) > 500:\n",
        "    print(f\"... +{len(pred_language_string)-500} chars\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optional: Batch Processing\n",
        "Uncomment the cell below to process all files in batch mode."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 9: Batch Process All Files (Optional)\n",
        "# Uncomment to run batch processing\n",
        "\n",
        "for point_cloud_file in tqdm(point_cloud_files):\n",
        "    point_cloud = load_o3d_pcd(str(point_cloud_file))\n",
        "    grid_size = Layout.get_grid_size(num_bins)\n",
        "    if not no_cleanup:\n",
        "        point_cloud = cleanup_pcd(point_cloud, voxel_size=grid_size)\n",
        "    points, colors = get_points_and_colors(point_cloud)\n",
        "    min_extent = np.min(points, axis=0)\n",
        "    input_pcd = preprocess_point_cloud(points, colors, grid_size, num_bins)\n",
        "    layout = generate_layout(model, input_pcd, tokenizer, code_template_file,\n",
        "                             top_k=top_k, top_p=top_p, temperature=temperature,\n",
        "                             num_beams=num_beams, seed=seed, detect_type=detect_type,\n",
        "                             categories=categories)\n",
        "    layout.translate(min_extent)\n",
        "    pred_language_string = layout.to_language_string()\n",
        "    if os.path.splitext(output_path)[-1]:\n",
        "        with open(output_path, \"w\") as f:\n",
        "            f.write(pred_language_string)\n",
        "    else:\n",
        "        output_filename = os.path.basename(point_cloud_file).replace(\".ply\", \".txt\")\n",
        "        os.makedirs(output_path, exist_ok=True)\n",
        "        with open(os.path.join(output_path, output_filename), \"w\") as f:\n",
        "            f.write(pred_language_string)\n",
        "print(f\"âœ“ Batch complete: {len(point_cloud_files)} files\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "spatiallm",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
