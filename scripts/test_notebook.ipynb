{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SpatialLM Inference Notebook\n",
        "This notebook breaks down the inference.py workflow into interactive cells."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 1: Imports and Constants\n",
        "import os\n",
        "import sys\n",
        "import glob\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from threading import Thread\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from transformers import TextIteratorStreamer, set_seed\n",
        "\n",
        "# Add project root to path\n",
        "PROJ_PATH = \"/mnt/cluster/workspaces/jinjingxu/proj/vlm/SpatialLM\"\n",
        "DATA_ROOT = '/data/horse/ws/jixu233b-metadata_ws/datasets/arkitscenes-spatiallm/'\n",
        "DATA_ROOT = '/mnt/nct-zfs/TCO-All/SharedDatasets/arkitscenes-spatiallm/'\n",
        "\n",
        "PROJECT_ROOT = Path(PROJ_PATH)\n",
        "sys.path.insert(0, str(PROJECT_ROOT))\n",
        "\n",
        "from spatiallm import Layout\n",
        "from spatiallm.pcd import load_o3d_pcd, get_points_and_colors, cleanup_pcd, Compose\n",
        "\n",
        "DETECT_TYPE_PROMPT = {\n",
        "    \"all\": \"Detect walls, doors, windows, boxes.\",\n",
        "    \"arch\": \"Detect walls, doors, windows.\",\n",
        "    \"object\": \"Detect boxes.\",\n",
        "}\n",
        "\n",
        "print(\"✓ Imports loaded\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 2: Define Helper Functions\n",
        "\n",
        "def preprocess_point_cloud(points, colors, grid_size, num_bins):\n",
        "    \"\"\"Preprocess point cloud into tensor features.\"\"\"\n",
        "    transform = Compose([\n",
        "        dict(type=\"PositiveShift\"),\n",
        "        dict(type=\"NormalizeColor\"),\n",
        "        dict(\n",
        "            type=\"GridSample\",\n",
        "            grid_size=grid_size,\n",
        "            hash_type=\"fnv\",\n",
        "            mode=\"test\",\n",
        "            keys=(\"coord\", \"color\"),\n",
        "            return_grid_coord=True,\n",
        "            max_grid_coord=num_bins,\n",
        "        ),\n",
        "    ])\n",
        "    point_cloud = transform({\n",
        "        \"name\": \"pcd\",\n",
        "        \"coord\": points.copy(),\n",
        "        \"color\": colors.copy(),\n",
        "    })\n",
        "    coord = point_cloud[\"grid_coord\"]\n",
        "    xyz = point_cloud[\"coord\"]\n",
        "    rgb = point_cloud[\"color\"]\n",
        "    point_cloud = np.concatenate([coord, xyz, rgb], axis=1)\n",
        "    return torch.as_tensor(np.stack([point_cloud], axis=0))\n",
        "\n",
        "\n",
        "def generate_layout(model, point_cloud, tokenizer, code_template_file, \n",
        "                    top_k=10, top_p=0.95, temperature=0.6, num_beams=1,\n",
        "                    seed=-1, max_new_tokens=4096, detect_type=\"all\", categories=[]):\n",
        "    \"\"\"Generate layout from point cloud using the model.\"\"\"\n",
        "    if seed >= 0:\n",
        "        set_seed(seed)\n",
        "    \n",
        "    with open(code_template_file, \"r\") as f:\n",
        "        code_template = f.read()\n",
        "    \n",
        "    task_prompt = DETECT_TYPE_PROMPT[detect_type]\n",
        "    if detect_type != \"arch\" and categories:\n",
        "        task_prompt = task_prompt.replace(\"boxes\", \", \".join(categories))\n",
        "    print(\"Task prompt:\", task_prompt)\n",
        "    \n",
        "    prompt = f\"<|point_start|><|point_pad|><|point_end|>{task_prompt} The reference code is as followed: {code_template}\"\n",
        "    \n",
        "    if model.config.model_type == \"spatiallm_qwen\":\n",
        "        conversation = [\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt},\n",
        "        ]\n",
        "    else:\n",
        "        conversation = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    \n",
        "    input_ids = tokenizer.apply_chat_template(conversation, add_generation_prompt=True, return_tensors=\"pt\")\n",
        "    input_ids = input_ids.to(model.device)\n",
        "    \n",
        "    streamer = TextIteratorStreamer(tokenizer, timeout=20.0, skip_prompt=True, skip_special_tokens=True)\n",
        "    \n",
        "    generate_kwargs = dict(\n",
        "        {\"input_ids\": input_ids, \"point_clouds\": point_cloud},\n",
        "        streamer=streamer,\n",
        "        max_new_tokens=max_new_tokens,\n",
        "        do_sample=True,\n",
        "        use_cache=True,\n",
        "        temperature=temperature,\n",
        "        top_p=top_p,\n",
        "        top_k=top_k,\n",
        "        num_beams=num_beams,\n",
        "    )\n",
        "    t = Thread(target=model.generate, kwargs=generate_kwargs)\n",
        "    t.start()\n",
        "    \n",
        "    print(\"Generating layout...\\\\n\")\n",
        "    generate_texts = []\n",
        "    for text in streamer:\n",
        "        generate_texts.append(text)\n",
        "        print(text, end=\"\", flush=True)\n",
        "    print(\"\\\\nDone!\")\n",
        "    \n",
        "    layout_str = \"\".join(generate_texts)\n",
        "    layout = Layout(layout_str)\n",
        "    layout.undiscretize_and_unnormalize(num_bins=model.config.point_config[\"num_bins\"])\n",
        "    return layout\n",
        "\n",
        "print(\"✓ Helper functions defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 3: Set Parameters\n",
        "DATA_ROOT = Path(DATA_ROOT)\n",
        "\n",
        "# Input/Output paths\n",
        "point_cloud_path = DATA_ROOT / \"pcd/40753679.ply\"\n",
        "output_path = PROJECT_ROOT / \"outputs/scene40753679.txt\"\n",
        "\n",
        "# Model configuration\n",
        "model_path = \"manycore-research/SpatialLM1.1-Qwen-0.5B\"\n",
        "\n",
        "# Inference parameters\n",
        "detect_type = \"all\"\n",
        "categories = []\n",
        "code_template_file = str(PROJECT_ROOT / \"code_template.txt\")\n",
        "\n",
        "# Generation parameters\n",
        "top_k = 10\n",
        "top_p = 0.95\n",
        "temperature = 0.6\n",
        "num_beams = 1\n",
        "seed = -1\n",
        "max_new_tokens = 4096\n",
        "inference_dtype = \"bfloat16\"\n",
        "no_cleanup = False\n",
        "\n",
        "# Optional: JSON file to filter specific samples\n",
        "json_file = None\n",
        "\n",
        "print(\"✓ Parameters configured\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 4: Diagnostic - Check CUDA Status\n",
        "import torch\n",
        "import sys\n",
        "\n",
        "print(\"=== CUDA Diagnostic ===\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "print(f\"CUDA version: {torch.version.cuda}\")\n",
        "print(f\"CUDA device count: {torch.cuda.device_count()}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"Current CUDA device: {torch.cuda.current_device()}\")\n",
        "    print(f\"Device name: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"Device capability: {torch.cuda.get_device_capability(0)}\")\n",
        "\n",
        "print(f\"\\nPython executable: {sys.executable}\")\n",
        "print(f\"Python version: {sys.version.split()[0]}\")\n",
        "\n",
        "# Try to initialize CUDA explicitly\n",
        "try:\n",
        "    torch.cuda.init()\n",
        "    print(\"\\n✓ CUDA initialization successful\")\n",
        "except Exception as e:\n",
        "    print(f\"\\n✗ CUDA initialization failed: {e}\")\n",
        "\n",
        "# Try to create a small tensor on CUDA\n",
        "try:\n",
        "    test_tensor = torch.zeros(1).cuda()\n",
        "    print(f\"✓ Test tensor created on CUDA: {test_tensor.device}\")\n",
        "    del test_tensor\n",
        "except Exception as e:\n",
        "    print(f\"✗ Failed to create tensor on CUDA: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 4: Load Model and Tokenizer\n",
        "print(f\"Loading model from {model_path}...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_path, torch_dtype=getattr(torch, inference_dtype))\n",
        "model.to(\"cuda\")\n",
        "model.set_point_backbone_dtype(torch.float32)\n",
        "model.eval()\n",
        "\n",
        "num_bins = model.config.point_config[\"num_bins\"]\n",
        "\n",
        "print(f\"✓ Model loaded\")\n",
        "print(f\"  - Type: {model.config.model_type}\")\n",
        "print(f\"  - Bins: {num_bins}\")\n",
        "print(f\"  - Device: {model.device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('Pointcloud path: ', point_cloud_path)\n",
        "# Cell 5: Discover Point Cloud Files\n",
        "if os.path.isfile(point_cloud_path):\n",
        "    point_cloud_files = [point_cloud_path]\n",
        "else:\n",
        "    if json_file is not None:\n",
        "        print(f\"Loading samples from JSON: {json_file}\")\n",
        "        with open(json_file, \"r\") as f:\n",
        "            json_data = json.load(f)\n",
        "        \n",
        "        point_cloud_files = []\n",
        "        for item in json_data:\n",
        "            pcd_files = []\n",
        "            if isinstance(item, str):\n",
        "                pcd_files = [item]\n",
        "            elif isinstance(item, dict):\n",
        "                value = (item.get(\"point_clouds\") or item.get(\"point_cloud\") or \n",
        "                        item.get(\"file_name\") or item.get(\"pcd_file\") or \n",
        "                        item.get(\"scene_id\") or item.get(\"id\"))\n",
        "                pcd_files = value if isinstance(value, list) else [value] if value else []\n",
        "            \n",
        "            for pcd_file in pcd_files:\n",
        "                pcd_file = pcd_file.replace(\"pcd/\", \"\")\n",
        "                if not pcd_file.endswith(\".ply\"):\n",
        "                    pcd_file = f\"{pcd_file}.ply\"\n",
        "                \n",
        "                full_path = os.path.join(point_cloud_path, pcd_file)\n",
        "                if os.path.exists(full_path):\n",
        "                    point_cloud_files.append(full_path)\n",
        "                else:\n",
        "                    print(f\"Warning: Not found: {full_path}\")\n",
        "        print(f\"Found {len(point_cloud_files)} samples from JSON\")\n",
        "    else:\n",
        "        point_cloud_files = glob.glob(os.path.join(point_cloud_path, \"*.ply\"))\n",
        "\n",
        "print(f\"✓ Found {len(point_cloud_files)} file(s)\")\n",
        "for i, f in enumerate(point_cloud_files[:5]):\n",
        "    print(f\"  [{i+1}] {os.path.basename(f)}\")\n",
        "if len(point_cloud_files) > 5:\n",
        "    print(f\"  ... +{len(point_cloud_files)-5} more\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 6: Load and Preprocess Point Cloud\n",
        "current_file_idx = 0\n",
        "point_cloud_file = point_cloud_files[current_file_idx]\n",
        "print(f\"Processing: {os.path.basename(point_cloud_file)}\")\n",
        "\n",
        "point_cloud = load_o3d_pcd(str(point_cloud_file))\n",
        "grid_size = Layout.get_grid_size(num_bins)\n",
        "\n",
        "if not no_cleanup:\n",
        "    point_cloud = cleanup_pcd(point_cloud, voxel_size=grid_size)\n",
        "\n",
        "points, colors = get_points_and_colors(point_cloud)\n",
        "min_extent = np.min(points, axis=0)\n",
        "\n",
        "print(f\"✓ Point cloud loaded\")\n",
        "print(f\"  - Points: {len(points)}\")\n",
        "print(f\"  - Range: {np.min(points, axis=0)} to {np.max(points, axis=0)}\")\n",
        "print(f\"  - Grid: {grid_size}\")\n",
        "\n",
        "input_pcd = preprocess_point_cloud(points, colors, grid_size, num_bins)\n",
        "print(f\"✓ Preprocessed: {input_pcd.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 7: Generate Layout\n",
        "layout = generate_layout(\n",
        "    model, input_pcd, tokenizer, code_template_file,\n",
        "    top_k=top_k, top_p=top_p, temperature=temperature,\n",
        "    num_beams=num_beams, seed=seed, detect_type=detect_type,\n",
        "    categories=categories\n",
        ")\n",
        "\n",
        "layout.translate(min_extent)\n",
        "print(f\"\\\\n✓ Layout generated\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 8: Save Output\n",
        "pred_language_string = layout.to_language_string()\n",
        "\n",
        "if os.path.splitext(output_path)[-1]:\n",
        "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
        "    with open(output_path, \"w\") as f:\n",
        "        f.write(pred_language_string)\n",
        "    print(f\"✓ Saved to: {output_path}\")\n",
        "else:\n",
        "    output_filename = os.path.basename(point_cloud_file).replace(\".ply\", \".txt\")\n",
        "    os.makedirs(output_path, exist_ok=True)\n",
        "    output_file = os.path.join(output_path, output_filename)\n",
        "    with open(output_file, \"w\") as f:\n",
        "        f.write(pred_language_string)\n",
        "    print(f\"✓ Saved to: {output_file}\")\n",
        "\n",
        "print(\"\\\\n--- Preview (500 chars) ---\")\n",
        "print(pred_language_string[:500])\n",
        "if len(pred_language_string) > 500:\n",
        "    print(f\"... +{len(pred_language_string)-500} chars\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optional: Batch Processing\n",
        "Uncomment the cell below to process all files in batch mode."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 9: Batch Process All Files (Optional)\n",
        "# Uncomment to run batch processing\n",
        "\n",
        "# for point_cloud_file in tqdm(point_cloud_files):\n",
        "#     point_cloud = load_o3d_pcd(str(point_cloud_file))\n",
        "#     grid_size = Layout.get_grid_size(num_bins)\n",
        "#     if not no_cleanup:\n",
        "#         point_cloud = cleanup_pcd(point_cloud, voxel_size=grid_size)\n",
        "#     points, colors = get_points_and_colors(point_cloud)\n",
        "#     min_extent = np.min(points, axis=0)\n",
        "#     input_pcd = preprocess_point_cloud(points, colors, grid_size, num_bins)\n",
        "#     layout = generate_layout(model, input_pcd, tokenizer, code_template_file,\n",
        "#                              top_k=top_k, top_p=top_p, temperature=temperature,\n",
        "#                              num_beams=num_beams, seed=seed, detect_type=detect_type,\n",
        "#                              categories=categories)\n",
        "#     layout.translate(min_extent)\n",
        "#     pred_language_string = layout.to_language_string()\n",
        "#     if os.path.splitext(output_path)[-1]:\n",
        "#         with open(output_path, \"w\") as f:\n",
        "#             f.write(pred_language_string)\n",
        "#     else:\n",
        "#         output_filename = os.path.basename(point_cloud_file).replace(\".ply\", \".txt\")\n",
        "#         os.makedirs(output_path, exist_ok=True)\n",
        "#         with open(os.path.join(output_path, output_filename), \"w\") as f:\n",
        "#             f.write(pred_language_string)\n",
        "# print(f\"✓ Batch complete: {len(point_cloud_files)} files\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "spatiallm",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
