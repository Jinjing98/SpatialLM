### model
model_name_or_path: manycore-research/SpatialLM1.1-Qwen-0.5B
trust_remote_code: true

### 3D Positional Encoding Configuration (uncomment to enable)
VLM_PE: "CCA_2DProj"         # Options: null (default 1D RoPE), "CCA_2DProj", "3D_RoPE", "3D_Sinusoidal"
disable_flash_attn: false      # Whether to disable flash attention (default: false)
media_dir: /mnt/nct-zfs/TCO-All/SharedDatasets/arkitscenes-spatiallm # arkitscenes-spatiallm
### method
do_train: true
freeze_language_tower: false
freeze_point_tower: false
train_proj_only: false

### dataset
dataset: arkitscenes_train # arkitscenes_train,arkitscenes_val
dataset_dir: /mnt/nct-zfs/TCO-All/SharedDatasets/arkitscenes-spatiallm # arkitscenes-spatiallm
template: spatiallm_qwen # spatiallm_qwen, spatiallm_llama
num_bins: 1280
do_augmentation: false
random_rotation: true
cutoff_len: 8192
overwrite_cache: true
# JJ
preprocessing_num_workers: 1
dataloader_num_workers: 1
# save_dir: saves/arkitscenes
save_dir: /mnt/nct-zfs/TCO-Test/jinjingxu/exps/train/saves/arkitscenes

### output
# output_dir: saves
# output_dir: /mnt/nct-zfs/TCO-Test/jinjingxu/exps/train/saves
# Note: Timestamp auto-appended (e.g., spatiallm_0126_153045). Disable: AUTO_TIMESTAMP_OUTPUT_DIR=0
output_dir: /mnt/nct-zfs/TCO-Test/jinjingxu/exps/train/spatiallm
logging_steps: 10
save_steps: 500
overwrite_output_dir: false
save_total_limit: 5

### train
per_device_train_batch_size: 1
gradient_accumulation_steps: 1
learning_rate: 1.0e-5 # to be more aggressive: try to change the learning rate to 5.0e-5 or 1.0e-4
num_train_epochs: 10
lr_scheduler_type: cosine
warmup_ratio: 0.03
pure_bf16: false
bf16: false
fp16: false
tf32: true
ddp_timeout: 180000000
report_to: none # choices: [none, wandb, tensorboard, swanlab]
max_new_tokens: 4096

### eval
val_size: 0.0001
per_device_eval_batch_size: 1
eval_strategy: steps
eval_steps: 500
